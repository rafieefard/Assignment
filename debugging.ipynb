{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "16dd0e54-1177-41f7-a262-2b4c8bf37c63",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from typing import Set,Tuple, List\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "NoneType = type(None)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import vgg11\n",
    "from torchvision.models import mobilenet_v2\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cc882a7b-ee15-441c-8f29-7a88334928d4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"exercise-1\"><strong>Exercise 1</strong></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "5361b734-8aa8-4f12-8749-ff1ab0d84c8b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>This method returns the fruit name by getting the string at a specific index of the set.</p>\n",
    "<dl>\n",
    "<dt>param fruit_id</dt>\n",
    "<dd><p>The id of the fruit to get</p>\n",
    "</dd>\n",
    "<dt>param fruits</dt>\n",
    "<dd><p>The set of fruits to choose the id from</p>\n",
    "</dd>\n",
    "<dt>return</dt>\n",
    "<dd><p>The string corrosponding to the index <code>fruit_id</code></p>\n",
    "</dd>\n",
    "</dl>\n",
    "<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n",
    "<div class=\"line-block\"><code>1   It does not print the fruit at the correct index, why is the returned result wrong?</code><br />\n",
    "<code>2   How could this be fixed?</code></div>\n",
    "<p>This example demonstrates the issue: name1, name3 and name4 are expected to correspond to the strings at the indices 1, 3, and 4: 'orange', 'kiwi' and 'strawberry'..</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ed23d9b0-ae7a-4024-b39c-2824f8b5699e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def id_to_fruit(fruit_id: int, fruits: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    This method returns the fruit name by getting the string at a specific index of the set.\n",
    "\n",
    "    :param fruit_id: The id of the fruit to get\n",
    "    :param fruits: The set of fruits to choose the id from\n",
    "    :return: The string corrosponding to the index ``fruit_id``\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    | ``1   It does not print the fruit at the correct index, why is the returned result wrong?``\n",
    "    | ``2   How could this be fixed?``\n",
    "\n",
    "    This example demonstrates the issue:\n",
    "    name1, name3 and name4 are expected to correspond to the strings at the indices 1, 3, and 4:\n",
    "    'orange', 'kiwi' and 'strawberry'..\n",
    "\n",
    "    >>> name1 = id_to_fruit(1, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    >>> name3 = id_to_fruit(3, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    >>> name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for fruit in fruits:\n",
    "        if fruit_id == idx:\n",
    "            return fruit\n",
    "        idx += 1\n",
    "    raise RuntimeError(f\"Fruit with id {fruit_id} does not exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "025aaa96-8477-4a10-bb5d-d705e81d8aa1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "name1 = id_to_fruit(1, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "name3 = id_to_fruit(3, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange apple kiwi\n"
     ]
    }
   ],
   "source": [
    "print(name1, name3, name4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"exercise-1\"><strong>Exercise 1 Answer</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3px\">\n",
    "<p>1. It returns the wrong answer because the set variable type is unordered. So, every time the code is run, the results may change.</p>\n",
    "<p>2. To solve the problem, the input data needs to be in the form of a list variable type.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = id_to_fruit(1, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])\n",
    "name3 = id_to_fruit(3, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])\n",
    "name4 = id_to_fruit(4, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange kiwi strawberry\n"
     ]
    }
   ],
   "source": [
    "print(name1, name3, name4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ae288313-4e91-4a31-8c2d-dc06c7b65a74",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"exercise-2\"><strong>Exercise 2</strong></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "4cd5165e-4013-40fb-9a86-82f4080fcf9d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>This method will flip the x and y coordinates in the coords array.</p>\n",
    "<dl>\n",
    "<dt>param coords</dt>\n",
    "<dd><p>A numpy array of bounding box coordinates with shape [n,5] in format: :</p>\n",
    "<pre><code>[[x11, y11, x12, y12, classid1],\n",
    " [x21, y21, x22, y22, classid2],\n",
    " ...\n",
    " [xn1, yn1, xn2, yn2, classid3]]</code></pre>\n",
    "</dd>\n",
    "<dt>return</dt>\n",
    "<dd><p>The new numpy array where the x and y coordinates are flipped.</p>\n",
    "</dd>\n",
    "</dl>\n",
    "<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n",
    "<div class=\"line-block\"><code>1   Can you spot the obvious error?</code><br />\n",
    "<code>2   After fixing the obvious error it is still wrong, how can this be fixed?</code></div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "305f143b-0d43-417d-8478-045e258c1d2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>The example demonstrates the issue. The returned swapped_coords are expected to have swapped x and y coordinates in each of the rows.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a9498a72-2a4d-4d03-bcce-fe07e85756ec",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def swap(coords: np.ndarray):\n",
    "    \"\"\"\n",
    "    This method will flip the x and y coordinates in the coords array.\n",
    "\n",
    "    :param coords: A numpy array of bounding box coordinates with shape [n,5] in format:\n",
    "        ::\n",
    "\n",
    "            [[x11, y11, x12, y12, classid1],\n",
    "             [x21, y21, x22, y22, classid2],\n",
    "             ...\n",
    "             [xn1, yn1, xn2, yn2, classid3]]\n",
    "\n",
    "    :return: The new numpy array where the x and y coordinates are flipped.\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    | ``1   Can you spot the obvious error?``\n",
    "    | ``2   After fixing the obvious error it is still wrong, how can this be fixed?``\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> coords = np.array([[10, 5, 15, 6, 0],\n",
    "    ...                    [11, 3, 13, 6, 0],\n",
    "    ...                    [5, 3, 13, 6, 1],\n",
    "    ...                    [4, 4, 13, 6, 1],\n",
    "    ...                    [6, 5, 13, 16, 1]])\n",
    "    >>> swapped_coords = swap(coords)\n",
    "\n",
    "    The example demonstrates the issue. The returned swapped_coords are expected to have swapped\n",
    "    x and y coordinates in each of the rows.\n",
    "    \"\"\"\n",
    "    coords[:, 0], coords[:, 1], coords[:, 2], coords[:, 3], = coords[:, 1], coords[:, 1], coords[:, 3], coords[:, 2]\n",
    "    return coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coords = np.array([[10, 5, 15, 6, 0],\n",
    "                   [11, 3, 13, 6, 0],\n",
    "                   [5, 3, 13, 6, 1],\n",
    "                   [4, 4, 13, 6, 1],\n",
    "                   [6, 5, 13, 16, 1]])\n",
    "swapped_coords = swap(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  5  6  6  0]\n",
      " [ 3  3  6  6  0]\n",
      " [ 3  3  6  6  1]\n",
      " [ 4  4  6  6  1]\n",
      " [ 5  5 16 16  1]]\n"
     ]
    }
   ],
   "source": [
    "print(swapped_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"exercise-2\"><strong>Exercise 2 Answer</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3px\">\n",
    "<p>1. The obvious error is located in line 33, as following:</p>\n",
    "<p><code>coords[:, 0], coords[:, 1], coords[:, 2], coords[:, 3], = coords[:, 1], coords[:, 1], coords[:, 3], coords[:, 2]</code></p>\n",
    "<p>To fix it, the code needs to be revised according to the following code:</p>\n",
    "<p>coords[:, 0], coords[:, 1], coords[:, 2], coords[:, 3], = coords[:, 1], <code>coords[:, 0]</code>, coords[:, 3], coords[:, 2]</p>\n",
    "<br>\n",
    "<p>2. After fixing the obvious error with following revised function the output will be correct.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_swap(coords: np.ndarray):\n",
    "    new_coords = coords.copy()\n",
    "    new_coords[:, 0], new_coords[:, 1], new_coords[:, 2], new_coords[:, 3], = coords[:, 1], coords[:, 0], coords[:, 3], coords[:, 2]\n",
    "    return new_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "28f520e2-11c8-4646-9917-b0c07eec0da8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coords = np.array([[10, 5, 15, 6, 0],\n",
    "                   [11, 3, 13, 6, 0],\n",
    "                   [5, 3, 13, 6, 1],\n",
    "                   [4, 4, 13, 6, 1],\n",
    "                   [6, 5, 13, 16, 1]])\n",
    "swapped_coords = fixed_swap(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 10  6 15  0]\n",
      " [ 3 11  6 13  0]\n",
      " [ 3  5  6 13  1]\n",
      " [ 4  4  6 13  1]\n",
      " [ 5  6 16 13  1]]\n"
     ]
    }
   ],
   "source": [
    "print(swapped_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a1f01da3-8770-45ca-8d36-92c35558dd17",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"exercise-3\"><strong>Exercise 3</strong></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "3f04f9e6-5411-42a9-a244-3cf2f1ab3171",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>This code plots the precision-recall curve based on data from a .csv file, where precision is on the x-axis and recall is on the y-axis. It it not so important right now what precision and recall means.</p>\n",
    "<dl>\n",
    "<dt>param csv_file_path</dt>\n",
    "<dd><p>The CSV file containing the data to plot.</p>\n",
    "</dd>\n",
    "</dl>\n",
    "<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n",
    "<div class=\"line-block\"><code>1   For some reason the plot is not showing correctly, can you find out what is going wrong?</code><br />\n",
    "<code>2   How could this be fixed?</code></div>\n",
    "<p>This example demonstrates the issue. It first generates some data in a csv file format and the plots it using the <code>plot_data</code> method. If you manually check the coordinates and then check the plot, they do not correspond.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "94c9cc8b-f0eb-47d5-b03d-12368e976de5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def plot_data(csv_file_path: str):\n",
    "    \"\"\"\n",
    "    This code plots the precision-recall curve based on data from a .csv file,\n",
    "    where precision is on the x-axis and recall is on the y-axis.\n",
    "    It it not so important right now what precision and recall means.\n",
    "\n",
    "    :param csv_file_path: The CSV file containing the data to plot.\n",
    "\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    | ``1   For some reason the plot is not showing correctly, can you find out what is going wrong?``\n",
    "    | ``2   How could this be fixed?``\n",
    "\n",
    "    This example demonstrates the issue.\n",
    "    It first generates some data in a csv file format and the plots it using the ``plot_data`` method.\n",
    "    If you manually check the coordinates and then check the plot, they do not correspond.\n",
    "\n",
    "    >>> f = open(\"data_file.csv\", \"w\")\n",
    "    >>> w = csv.writer(f)\n",
    "    >>> _ = w.writerow([\"precision\", \"recall\"])\n",
    "    >>> w.writerows([[0.013,0.951],\n",
    "    ...              [0.376,0.851],\n",
    "    ...              [0.441,0.839],\n",
    "    ...              [0.570,0.758],\n",
    "    ...              [0.635,0.674],\n",
    "    ...              [0.721,0.604],\n",
    "    ...              [0.837,0.531],\n",
    "    ...              [0.860,0.453],\n",
    "    ...              [0.962,0.348],\n",
    "    ...              [0.982,0.273],\n",
    "    ...              [1.0,0.0]])\n",
    "    >>> f.close()\n",
    "    >>> plot_data('data_file.csv')\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    results = []\n",
    "    with open(csv_file_path) as result_csv:\n",
    "        csv_reader = csv.reader(result_csv, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        results = np.stack(results)\n",
    "\n",
    "    # plot precision-recall curve\n",
    "    plt.plot(results[:, 1], results[:, 0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "7d3fe2ec-aef4-44ec-8240-c292c43d0ec5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"data_file.csv\", \"w\", newline='')\n",
    "w = csv.writer(f)\n",
    "_ = w.writerow([\"precision\", \"recall\"])\n",
    "w.writerows([[0.013,0.951],\n",
    "             [0.376,0.851],\n",
    "             [0.441,0.839],\n",
    "             [0.570,0.758],\n",
    "             [0.635,0.674],\n",
    "             [0.721,0.604],\n",
    "             [0.837,0.531],\n",
    "             [0.860,0.453],\n",
    "             [0.962,0.348],\n",
    "             [0.982,0.273],\n",
    "             [1.0,0.0]])\n",
    "f.close()\n",
    "plot_data('data_file.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"exercise-3\"><strong>Exercise 3 Answer</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3px\">\n",
    "<p>1. The problem has arisen because the data read from CSV file is in string format. Therefore the issue is related to the line 44, as follows:</p>\n",
    "<p><code>results.append(row)</code></p>\n",
    "<p>Whereby, string values are placed in the <code>results</code> list instead of numerical values.</p>\n",
    "</br>\n",
    "<p>2. To correct this, after reading each row, I converted its string elements to float elements.</p>\n",
    "<p>It is worth mentioning that I made another change to the original code to ensure it runs without errors.</p>\n",
    "<p>This modification was necessary because I encountered an error due to the data being written in CSV file with an additional blank line between rows.</p>\n",
    "<p>To solve this issue, I changed the first line to <code>f = open(\"data_file.csv\", \"w\", newline='')</code></p>\n",
    "<p>This issue may have arisen due to the Python version.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def fixed_plot_data(csv_file_path: str):\n",
    "    # load data\n",
    "    results = []\n",
    "    with open(csv_file_path) as result_csv:\n",
    "        csv_reader = csv.reader(result_csv, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            # Convert the string coordinates to float.\n",
    "            numerical_row = [float(item) for item in row]\n",
    "            results.append(numerical_row)\n",
    "        results = np.stack(results)\n",
    "\n",
    "    # plot precision-recall curve\n",
    "    plt.plot(results[:, 1], results[:, 0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avoid inserting additionl blank line between rows\n",
    "f = open(\"data_file.csv\", \"w\", newline='')\n",
    "w = csv.writer(f)\n",
    "_ = w.writerow([\"precision\", \"recall\"])\n",
    "w.writerows([[0.013,0.951],\n",
    "             [0.376,0.851],\n",
    "             [0.441,0.839],\n",
    "             [0.570,0.758],\n",
    "             [0.635,0.674],\n",
    "             [0.721,0.604],\n",
    "             [0.837,0.531],\n",
    "             [0.860,0.453],\n",
    "             [0.962,0.348],\n",
    "             [0.982,0.273],\n",
    "             [1.0,0.0]])\n",
    "f.close()\n",
    "fixed_plot_data('data_file.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "e5847fdf-e1ac-4ed6-afcf-3770d90f09b3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"generator-for-exercise-4\">** Generator (for Exercise 4)**</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "c44ce22c-62b5-4b4e-a21c-d5fa92fa0c0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>Generator class for the GAN</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "b6fc98b2-8167-4b7f-bfcb-c89e1b641d19",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator class for the GAN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, 28, 28)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "edf16cad-258f-487a-a943-add21d1f133a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"discriminator-for-exercise-4\">** Discriminator (for Exercise 4)**</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "64cb9d71-aa84-4f28-9c16-c84ae48a3c44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>Discriminator class for the GAN</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "794a7f53-5d26-4027-a411-02e35c7a17a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator class for the GAN\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eabb4be5-9c19-44d2-a468-21d8adb038b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1 id=\"exercise-4\">** Exercise 4**</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "7bd45bd0-09eb-41d5-9ac7-cbb4a648d45f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font size=\"4px\"><p>The method trains a Generative Adversarial Network and is based on: <a href=\"https://realpython.com/generative-adversarial-networks/\">https://realpython.com/generative-adversarial-networks/</a></p>\n",
    "<p>The Generator network tries to generate convincing images of handwritten digits. The Discriminator needs to detect if the image was created by the Generater or if the image is a real image from a known dataset (MNIST). If both the Generator and the Discriminator are optimized, the Generator is able to create images that are difficult to distinguish from real images. This is goal of a GAN.</p>\n",
    "<p>This code produces the expected results at first attempt at about 50 epochs.</p>\n",
    "<dl>\n",
    "<dt>param batch_size</dt>\n",
    "<dd><p>The number of images to train in one epoch.</p>\n",
    "</dd>\n",
    "<dt>param num_epochs</dt>\n",
    "<dd><p>The number of epochs to train the gan.</p>\n",
    "</dd>\n",
    "<dt>param device</dt>\n",
    "<dd><p>The computing device to use. If CUDA is installed and working then <span class=\"title-ref\">cuda:0</span> is chosen otherwise 'cpu' is chosen. Note: Training a GAN on the CPU is very slow.</p>\n",
    "</dd>\n",
    "</dl>\n",
    "<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n",
    "<p>It contains at least two bugs: one structural bug and one cosmetic bug. Both bugs are from the original tutorial.</p>\n",
    "<div class=\"line-block\"><code>1   Changing the batch_size from 32 to 64 triggers the structural bug.</code><br />\n",
    "<code>2   Can you also spot the cosmetic bug?</code><br />\n",
    "<code>Note: to fix this bug a thorough understanding of GANs is not necessary.</code></div>\n",
    "<p>Change the batch size to 64 to trigger the bug with message: ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\"</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "415e7df3-2d5e-4078-afa8-ab480906e127",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"\n",
    "    The method trains a Generative Adversarial Network and is based on:\n",
    "    https://realpython.com/generative-adversarial-networks/\n",
    "\n",
    "    The Generator network tries to generate convincing images of handwritten digits.\n",
    "    The Discriminator needs to detect if the image was created by the Generater or if the image is a real image from\n",
    "    a known dataset (MNIST).\n",
    "    If both the Generator and the Discriminator are optimized, the Generator is able to create images that are difficult\n",
    "    to distinguish from real images. This is goal of a GAN.\n",
    "\n",
    "    This code produces the expected results at first attempt at about 50 epochs.\n",
    "\n",
    "    :param batch_size: The number of images to train in one epoch.\n",
    "    :param num_epochs: The number of epochs to train the gan.\n",
    "    :param device: The computing device to use. If CUDA is installed and working then `cuda:0` is chosen\n",
    "        otherwise 'cpu' is chosen. Note: Training a GAN on the CPU is very slow.\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    It contains at least two bugs: one structural bug and one cosmetic bug. Both bugs are from the original tutorial.\n",
    "\n",
    "    | ``1   Changing the batch_size from 32 to 64 triggers the structural bug.``\n",
    "    | ``2   Can you also spot the cosmetic bug?``\n",
    "    | ``Note: to fix this bug a thorough understanding of GANs is not necessary.``\n",
    "\n",
    "    Change the batch size to 64 to trigger the bug with message:\n",
    "    ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\"\n",
    "\n",
    "    >>> train_gan(batch_size=32, num_epochs=100)\n",
    "    \"\"\"\n",
    "    # Add/adjust code.\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    try:\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    except:\n",
    "        print(\"Failed to download MNIST, retrying with different URL\")\n",
    "        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n",
    "        torchvision.datasets.MNIST.resources = [\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "             'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "             '9fb629c4189551a2d022fa330f9573f3'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "             'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # example data\n",
    "    real_samples, mnist_labels = next(iter(train_loader))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(16):\n",
    "        sub = fig.add_subplot(4, 4, 1 + i)\n",
    "        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "        sub.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Real images\")\n",
    "    display(fig)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Set up training\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    lr = 0.0001\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n",
    "\n",
    "            # Data for training the discriminator\n",
    "            real_samples = real_samples.to(device=device)\n",
    "            real_samples_labels = torch.ones((batch_size, 1)).to(device=device)\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            # Training the discriminator\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            # Data for training the generator\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "\n",
    "            # Training the generator\n",
    "            generator.zero_grad()\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "            # Show loss and samples generated\n",
    "            if n == batch_size - 1:\n",
    "                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n",
    "                generated_samples = generated_samples.detach().cpu().numpy()\n",
    "                fig = plt.figure()\n",
    "                for i in range(16):\n",
    "                    sub = fig.add_subplot(4, 4, 1 + i)\n",
    "                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                    sub.axis('off')\n",
    "                fig.suptitle(name)\n",
    "                fig.tight_layout()\n",
    "                clear_output(wait=False)\n",
    "                display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "f91ed112-98cc-49f1-a629-de2155a9ff30",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_gan(batch_size=32, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"exercise-4\"><strong>Exercise 4 Answer</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3px\">\n",
    "<p>1. The structural bug arises due to a mismatch between the number of the last batch of the training images with real sample and generated sample.</p>\n",
    "<p>When batch_size = 32, there isn't any problem because the number of train set images, which is 60000, is divisible by 32.</p>\n",
    "<p>However, with batch_size = 64 the last batch is contain 32 train images, instead of 64, because 60000 is not divisible by 64.</p>\n",
    "<p>To solve this isuue, I replace constant <code>batch_size</code> with <code>current_batch_size = real_samples.size(0)</code> to avoid problem in the last batch</p>\n",
    "</br>\n",
    "<p>2. The cosmetic bug is where the figures is displayed:</p>\n",
    "<p><code>for i in range(16):</code> in lines 29 and 85</p>\n",
    "<p>If the batch size is being less than 16, an error eccurs.</p>\n",
    "<p>To fix it, range number should be defined dynamically.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Add/adjust code.\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    try:\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    except:\n",
    "        print(\"Failed to download MNIST, retrying with different URL\")\n",
    "        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n",
    "        torchvision.datasets.MNIST.resources = [\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "             'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "             '9fb629c4189551a2d022fa330f9573f3'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "             'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # example data\n",
    "    real_samples, mnist_labels = next(iter(train_loader))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(16):\n",
    "        sub = fig.add_subplot(4, 4, 1 + i)\n",
    "        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "        sub.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Real images\")\n",
    "    display(fig)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Set up training\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    lr = 0.0001\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n",
    "            current_batch_size = real_samples.size(0)\n",
    "\n",
    "            # Data for training the discriminator\n",
    "            real_samples = real_samples.to(device=device)\n",
    "            real_samples_labels = torch.ones((current_batch_size, 1)).to(device=device)\n",
    "            latent_space_samples = torch.randn((current_batch_size, 100)).to(device=device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((current_batch_size, 1)).to(device=device)\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            # Training the discriminator\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            # Data for training the generator\n",
    "            latent_space_samples = torch.randn((current_batch_size, 100)).to(device=device)\n",
    "\n",
    "            # Training the generator\n",
    "            generator.zero_grad()\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "            # Show loss and samples generated\n",
    "            if n == current_batch_size - 1:\n",
    "                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n",
    "                generated_samples = generated_samples.detach().cpu().numpy()\n",
    "                fig = plt.figure()\n",
    "                for i in range(16):\n",
    "                    sub = fig.add_subplot(4, 4, 1 + i)\n",
    "                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                    sub.axis('off')\n",
    "                fig.suptitle(name)\n",
    "                fig.tight_layout()\n",
    "                \n",
    "                clear_output(wait=True)\n",
    "                display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_train_gan(batch_size=64, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
